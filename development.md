# Dynamic Underwriting Assistant - Development Guide

## ğŸ—ï¸ **Architecture Overview**

The Dynamic Underwriting Assistant is a sophisticated agentic AI application built using **LangGraph** for orchestrating multi-agent workflows, **Django** for the backend API, and **React** for the frontend interface. The system leverages **FAISS** for vector storage, **Groq LLM** for intelligent analysis, and **tiktoken** for text processing.

---

## ğŸ§  **Core Components Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FRONTEND (React)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Policy Mgr  â”‚ â”‚ Claims Mgr  â”‚ â”‚ Regulation  â”‚ â”‚ Embed  â”‚ â”‚
â”‚  â”‚             â”‚ â”‚             â”‚ â”‚ Manager     â”‚ â”‚ Serviceâ”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                          â”‚                                  â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚              â”‚  Underwriting Processor     â”‚                â”‚
â”‚              â”‚  (Main LangGraph Interface) â”‚                â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚ HTTP/REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   BACKEND (Django)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              API LAYER (Django REST)                   â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚Policy   â”‚ â”‚Claims   â”‚ â”‚Regulationâ”‚ â”‚Underwriting     â”‚ â”‚ â”‚
â”‚  â”‚  â”‚ViewSet  â”‚ â”‚ViewSet  â”‚ â”‚ViewSet   â”‚ â”‚ViewSet          â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                          â”‚                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                AGENTIC AI LAYER                        â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚              LangGraph Workflow                     â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚Data     â”‚ â”‚Embeddingâ”‚ â”‚Risk     â”‚ â”‚Flag         â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚Fetcher  â”‚ â”‚Service  â”‚ â”‚Analyzer â”‚ â”‚Explainer    â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚Agent    â”‚ â”‚Agent    â”‚ â”‚Agent    â”‚ â”‚Agent        â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                          â”‚                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                 DATA LAYER                              â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚Policy   â”‚ â”‚Claim    â”‚ â”‚Regulationâ”‚ â”‚UnderwritingApp  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚Model    â”‚ â”‚Model    â”‚ â”‚Model     â”‚ â”‚Model            â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â”‚                    Django ORM + SQLite                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                          â”‚                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              VECTOR STORAGE LAYER                      â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚   FAISS Index   â”‚ â”‚      Embedding Service         â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  (Vector Store) â”‚ â”‚   (Chunking + Embeddings)      â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                          â”‚                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚                 AI/LLM LAYER                            â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚               Groq LLM Integration                  â”‚ â”‚ â”‚
â”‚  â”‚  â”‚        (llama-3.1-8b-instant model)                â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ **LangGraph Workflow Architecture**

### **What is LangGraph?**
LangGraph is a framework for building stateful, multi-agent workflows using Large Language Models. It allows us to create complex AI systems where multiple specialized agents work together in a coordinated manner.

### **Our LangGraph Implementation:**

```python
class UnderwritingState(MessagesState):
    """State object that flows through the entire workflow"""
    applicant_id: str = ""
    policy_id: str = ""
    lob: str = ""
    application_data: Dict = {}
    policy_chunks: List[str] = []
    claims_chunks: List[str] = []
    regulations_chunks: List[str] = []
    risk_summary: str = ""
    red_flags: List[str] = []
    recommendations: str = ""
    explanation: str = ""
    task_complete: bool = False
    current_step: str = ""
```

### **Workflow Nodes (Agents):**

#### **1. Data Fetcher Agent** (`fetch_context_data`)
- **Purpose**: Retrieves relevant data from the database
- **Input**: Application identifiers (applicant_id, policy_id, lob)
- **Process**:
  ```python
  # Fetch policy data
  policy = Policy.objects.filter(policy_id=state["policy_id"]).first()
  
  # Fetch claims data  
  claims = Claim.objects.filter(applicant_id=state["applicant_id"])
  
  # Fetch regulations data
  regulations = Regulation.objects.filter(lob=state["lob"])
  ```
- **Output**: Raw text data for policies, claims, and regulations

#### **2. Embedding Service Agent** (`embed_and_retrieve`)
- **Purpose**: Processes and indexes text data, performs similarity search
- **Process**:
  ```python
  # Chunk documents using tiktoken
  chunks = self.embedding_service.chunk_text(text, chunk_size=500, overlap=50)
  
  # Generate embeddings (mock implementation)
  embeddings = self.embedding_service.get_embeddings(chunks)
  
  # Add to FAISS index
  self.embedding_service.add_to_index(texts, source, doc_id)
  
  # Perform similarity search
  relevant_chunks = self.embedding_service.search(query, k=15)
  ```
- **Output**: Relevant text chunks categorized by source

#### **3. Risk Analyzer Agent** (`summarize_risk`)
- **Purpose**: Uses Groq LLM to analyze risk and generate insights
- **Process**:
  ```python
  prompt = f"""As an insurance underwriting expert, analyze this application:
  
  APPLICATION DATA: {json.dumps(application_data, indent=2)}
  CONTEXT: {context_str}
  
  RISK SUMMARY: [assessment]
  RED FLAGS: [specific concerns]
  RECOMMENDATIONS: [actions]"""
  
  response = self.llm.invoke([HumanMessage(content=prompt)])
  ```
- **Output**: Structured risk analysis with flags and recommendations

#### **4. Flag Explainer Agent** (`explain_flag`)
- **Purpose**: Provides detailed explanations for specific risk flags
- **Process**: Uses LLM to generate comprehensive explanations
- **Output**: Detailed analysis of specific risk factors

### **Workflow Routing Logic:**

```python
def router(self, state: UnderwritingState) -> str:
    """Routes between workflow steps based on current state"""
    current_step = state.get("current_step", "fetch_context")
    
    if current_step == "error" or state.get("task_complete", False):
        return END
    elif current_step == "fetch_context":
        return "fetch_context"
    elif current_step == "embed_and_retrieve":
        return "embed_and_retrieve"
    elif current_step == "summarize_risk":
        return "summarize_risk"
    else:
        return END
```

---

## ğŸ—„ï¸ **Data Models & Storage**

### **Django Models:**

#### **1. Policy Model**
```python
class Policy(models.Model):
    id = models.UUIDField(primary_key=True, default=uuid.uuid4)
    policy_id = models.CharField(max_length=100, unique=True)
    text = models.TextField()  # Policy document content
    metadata = models.JSONField(default=dict)  # Structured data
    created_at = models.DateTimeField(auto_now_add=True)
```

**Purpose**: Stores insurance policy documents and terms
**Data Flow**: 
- Frontend â†’ Policy Manager â†’ API â†’ Policy Model â†’ Database
- Used by LangGraph for context retrieval

#### **2. Claim Model**
```python
class Claim(models.Model):
    id = models.UUIDField(primary_key=True, default=uuid.uuid4)
    applicant_id = models.CharField(max_length=100)
    text = models.TextField()  # Claim description
    metadata = models.JSONField(default=dict)
    lob = models.CharField(max_length=50)  # Line of Business
    created_at = models.DateTimeField(auto_now_add=True)
```

**Purpose**: Stores historical claims data for risk assessment
**Data Flow**:
- Frontend â†’ Claim Manager â†’ API â†’ Claim Model â†’ Database
- Retrieved by applicant_id during underwriting

#### **3. Regulation Model**
```python
class Regulation(models.Model):
    id = models.UUIDField(primary_key=True, default=uuid.uuid4)
    text = models.TextField()  # Regulation content
    metadata = models.JSONField(default=dict)
    lob = models.CharField(max_length=50)
    created_at = models.DateTimeField(auto_now_add=True)
```

**Purpose**: Stores regulatory requirements and compliance rules
**Data Flow**:
- Frontend â†’ Regulation Manager â†’ API â†’ Regulation Model â†’ Database
- Retrieved by line of business (lob) during underwriting

#### **4. UnderwritingApplication Model**
```python
class UnderwritingApplication(models.Model):
    id = models.UUIDField(primary_key=True, default=uuid.uuid4)
    applicant_id = models.CharField(max_length=100)
    policy_id = models.CharField(max_length=100)
    lob = models.CharField(max_length=50)
    application_data = models.JSONField()
    risk_summary = models.TextField(blank=True)
    red_flags = models.JSONField(default=list)
    recommendations = models.TextField(blank=True)
    status = models.CharField(max_length=50, default='pending')
    created_at = models.DateTimeField(auto_now_add=True)
```

**Purpose**: Stores processed underwriting applications and results
**Data Flow**:
- Created automatically when LangGraph workflow completes
- Stores all analysis results for future reference

---

## ğŸ” **Vector Storage & Embedding System**

### **FAISS Integration:**

```python
class EmbeddingService:
    def __init__(self):
        self.dimension = 1536  # Standard embedding dimension
        self.index = faiss.IndexFlatL2(self.dimension)  # L2 distance index
        self.chunk_metadata = []  # Metadata for each chunk
        self.encoding = tiktoken.get_encoding("gpt2")  # Tokenizer
```

### **Text Chunking Process:**
```python
def chunk_text(self, text: str, chunk_size: int = 500, overlap: int = 50):
    """Split text into overlapping chunks for better context preservation"""
    tokens = self.encoding.encode(text)
    chunks = []
    for i in range(0, len(tokens), chunk_size - overlap):
        chunk = self.encoding.decode(tokens[i: i + chunk_size])
        chunks.append(chunk)
    return chunks
```

**Why Chunking?**
- Large documents exceed LLM token limits
- Overlap ensures context continuity
- Smaller chunks improve search relevance

### **Embedding Generation:**
```python
def get_embeddings(self, texts: List[str]) -> List[List[float]]:
    """Generate vector embeddings for text chunks"""
    # Current: Mock implementation for testing
    # Production: Would use Groq's embedding API
    embeddings = []
    for text in texts:
        embedding = np.random.rand(self.dimension).tolist()
        embeddings.append(embedding)
    return embeddings
```

### **Vector Search Process:**
```python
def search(self, query: str, k: int = 5) -> List[Dict]:
    """Semantic search using FAISS index"""
    query_embedding = self.get_embeddings([query])[0]
    query_array = np.array([query_embedding], dtype=np.float32)
    
    distances, indices = self.index.search(query_array, min(k, self.index.ntotal))
    
    # Return relevant chunks with metadata
    results = []
    for i, idx in enumerate(indices[0]):
        if idx >= 0 and idx < len(self.chunk_metadata):
            result = self.chunk_metadata[idx].copy()
            result['distance'] = distances[0][i]
            results.append(result)
    return results
```

---

## ğŸ”„ **Complete Process Flow**

### **1. Data Ingestion Flow:**

```
Frontend Form â†’ API Endpoint â†’ Django Model â†’ Database
     â†“              â†“              â†“           â†“
Policy Mgr â†’ POST /api/policies/ â†’ Policy â†’ SQLite
Claims Mgr â†’ POST /api/claims/ â†’ Claim â†’ SQLite  
Regulation â†’ POST /api/regulations/ â†’ Regulation â†’ SQLite
```

### **2. Underwriting Process Flow:**

```
1. User Input (Frontend)
   â”œâ”€â”€ Applicant ID: "APP-001"
   â”œâ”€â”€ Policy ID: "POL-2024-001"
   â”œâ”€â”€ Line of Business: "auto"
   â””â”€â”€ Application Data: {
       "age": 22,
       "driving_record": "2 violations",
       "vehicle_type": "sports car",
       ...
   }

2. API Call
   POST /api/underwriting/process_application/
   â””â”€â”€ UnderwritingViewSet.process_application()

3. LangGraph Workflow Initialization
   initial_state = {
       "applicant_id": "APP-001",
       "policy_id": "POL-2024-001", 
       "lob": "auto",
       "application_data": {...},
       "current_step": "fetch_context"
   }

4. Workflow Execution:

   Step 1: Data Fetcher Agent
   â”œâ”€â”€ Query: Policy.objects.filter(policy_id="POL-2024-001")
   â”œâ”€â”€ Query: Claim.objects.filter(applicant_id="APP-001")
   â”œâ”€â”€ Query: Regulation.objects.filter(lob="auto")
   â””â”€â”€ Output: Raw text data

   Step 2: Embedding Service Agent  
   â”œâ”€â”€ Chunk texts using tiktoken (500 tokens, 50 overlap)
   â”œâ”€â”€ Generate embeddings for each chunk
   â”œâ”€â”€ Add to FAISS index with metadata
   â”œâ”€â”€ Create search query from application data
   â”œâ”€â”€ Perform similarity search (k=15)
   â””â”€â”€ Output: Relevant context chunks by source

   Step 3: Risk Analyzer Agent
   â”œâ”€â”€ Construct comprehensive prompt with:
   â”‚   â”œâ”€â”€ Application data (JSON format)
   â”‚   â”œâ”€â”€ Policy chunks (top 2)
   â”‚   â”œâ”€â”€ Claims chunks (top 2)
   â”‚   â””â”€â”€ Regulation chunks (top 2)
   â”œâ”€â”€ Send to Groq LLM (llama-3.1-8b-instant)
   â”œâ”€â”€ Parse structured response:
   â”‚   â”œâ”€â”€ Extract RISK SUMMARY section
   â”‚   â”œâ”€â”€ Extract RED FLAGS (lines starting with -)
   â”‚   â””â”€â”€ Extract RECOMMENDATIONS section
   â”œâ”€â”€ Apply fallback logic if parsing fails
   â””â”€â”€ Output: Risk analysis with flags

5. Result Storage
   â”œâ”€â”€ Create UnderwritingApplication record
   â”œâ”€â”€ Store all analysis results
   â””â”€â”€ Return response to frontend

6. Frontend Display
   â”œâ”€â”€ Show risk summary
   â”œâ”€â”€ Display red flags as clickable items
   â”œâ”€â”€ Show recommendations
   â””â”€â”€ Enable flag explanations
```

### **3. Flag Explanation Flow:**

```
1. User clicks red flag â†’ Frontend captures flag text
2. API Call: POST /api/underwriting/explain_flag/
3. LangGraph explain_flag() method
   â”œâ”€â”€ Construct explanation prompt
   â”œâ”€â”€ Include selected flag and context
   â”œâ”€â”€ Send to Groq LLM
   â””â”€â”€ Return detailed explanation
4. Frontend displays explanation in modal
```

---

## ğŸš€ **API Endpoints**

### **Core Endpoints:**

| Endpoint | Method | Purpose | Input | Output |
|----------|---------|---------|-------|--------|
| `/api/policies/` | GET/POST | Manage policies | Policy data | Policy list/created |
| `/api/claims/` | GET/POST | Manage claims | Claim data | Claim list/created |
| `/api/regulations/` | GET/POST | Manage regulations | Regulation data | Regulation list/created |
| `/api/underwriting/process_application/` | POST | Main workflow | Application data | Risk analysis |
| `/api/underwriting/explain_flag/` | POST | Flag explanation | Flag text + app ID | Detailed explanation |
| `/api/underwriting/embeddings/` | POST | Generate embeddings | Text array | Vector embeddings |

### **API Request/Response Examples:**

#### **Process Application:**
```json
// Request
{
  "applicant_id": "APP-001",
  "policy_id": "POL-2024-001",
  "lob": "auto", 
  "application_data": {
    "age": 22,
    "driving_record": "clean",
    "vehicle_type": "sedan"
  }
}

// Response  
{
  "application_id": "uuid-here",
  "risk_summary": "Low to moderate risk assessment...",
  "red_flags": [
    "Young driver (age 22) - higher risk demographic",
    "Limited driving experience"
  ],
  "recommendations": "Standard coverage with monitoring...",
  "status": "completed"
}
```

---

## ğŸ›ï¸ **Frontend Architecture**

### **React Component Structure:**

```
App.js
â”œâ”€â”€ Header.js (Navigation)
â””â”€â”€ UnderwritingDashboard.js
    â”œâ”€â”€ PolicyManager.js
    â”‚   â”œâ”€â”€ Add policy form
    â”‚   â”œâ”€â”€ Policy list display
    â”‚   â””â”€â”€ Policy details modal
    â”œâ”€â”€ ClaimManager.js
    â”‚   â”œâ”€â”€ Add claim form
    â”‚   â”œâ”€â”€ Claims list display
    â”‚   â””â”€â”€ Claim details modal
    â”œâ”€â”€ RegulationManager.js
    â”‚   â”œâ”€â”€ Add regulation form
    â”‚   â”œâ”€â”€ Regulations list display
    â”‚   â””â”€â”€ Regulation details modal
    â”œâ”€â”€ UnderwritingProcessor.js (Main Interface)
    â”‚   â”œâ”€â”€ Application form
    â”‚   â”œâ”€â”€ Processing status
    â”‚   â”œâ”€â”€ Results display
    â”‚   â”œâ”€â”€ Red flags with explanations
    â”‚   â””â”€â”€ Flag explanation modal
    â””â”€â”€ EmbeddingService.js
        â”œâ”€â”€ Text input form
        â”œâ”€â”€ Embedding generation
        â””â”€â”€ Results display
```

### **State Management:**
- **Local State**: Each component manages its own form data
- **API Communication**: Direct fetch calls to backend
- **Error Handling**: Toast notifications for errors
- **Loading States**: Visual feedback during API calls

---

## ğŸ”§ **Configuration & Environment**

### **Environment Variables:**
```bash
# Backend (.env)
GROQ_API_KEY=your_groq_api_key_here
DJANGO_SECRET_KEY=your_django_secret_key  
DEBUG=True
KMP_DUPLICATE_LIB_OK=TRUE  # For FAISS on macOS

# Frontend (.env)
REACT_APP_API_URL=http://localhost:8000
```

### **Key Dependencies:**

#### **Backend (requirements.txt):**
```
django==5.2.4
djangorestframework==3.16.0
django-cors-headers==4.7.0
langgraph                # Workflow orchestration
langchain-groq           # Groq LLM integration
faiss-cpu               # Vector storage
tiktoken                # Text tokenization
python-dotenv           # Environment variables
numpy                   # Numerical operations
```

#### **Frontend (package.json):**
```json
{
  "dependencies": {
    "react": "^18.2.0",
    "@chakra-ui/react": "^2.8.2",  // UI components
    "@emotion/react": "^11.11.1",   // Styling
    "framer-motion": "^10.16.4"     // Animations
  }
}
```

---

## ğŸ§ª **Testing Strategy**

### **Backend Testing:**
- **Unit Tests**: Individual component testing
- **Integration Tests**: API endpoint testing
- **Workflow Tests**: LangGraph execution testing
- **Mock Testing**: LLM response simulation

### **Frontend Testing:**
- **Component Tests**: React component rendering
- **Integration Tests**: API communication
- **E2E Tests**: Complete user workflows

---

## ğŸ”’ **Security Considerations**

1. **API Key Management**: Groq API key stored in environment variables
2. **CORS Configuration**: Controlled cross-origin requests
3. **Input Validation**: Form data validation on both ends
4. **Error Handling**: Graceful failure without exposing internals

---

## ğŸ“ˆ **Performance Optimizations**

1. **Chunking Strategy**: Optimal chunk size (500 tokens) with overlap
2. **Vector Search**: FAISS L2 index for fast similarity search
3. **Caching**: Component-level state management
4. **Lazy Loading**: On-demand data fetching

---

## ğŸš€ **Production Considerations**

### **Scalability:**
- **Database**: Migrate from SQLite to PostgreSQL
- **Vector Storage**: Distributed FAISS or Pinecone
- **LLM**: Production Groq API with rate limiting
- **Deployment**: Docker containers with orchestration

### **Monitoring:**
- **Logging**: Structured logging for workflow steps
- **Metrics**: API response times and success rates
- **Alerting**: Error rate monitoring

### **Security:**
- **Authentication**: JWT token-based auth
- **Authorization**: Role-based access control
- **Data Privacy**: PII encryption and anonymization

---

## ğŸ¯ **Key Benefits of This Architecture**

1. **Modularity**: Each agent has a specific responsibility
2. **Scalability**: Easy to add new agents or modify existing ones
3. **Maintainability**: Clear separation of concerns
4. **Extensibility**: Framework supports complex workflows
5. **Observability**: Full workflow state tracking
6. **Reliability**: Robust error handling and fallbacks

This architecture demonstrates how modern agentic AI systems can be built using LangGraph to create intelligent, multi-step workflows that combine the power of Large Language Models with traditional software engineering practices.
